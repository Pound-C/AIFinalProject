{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1650c6e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from urllib.parse import urlparse\n",
    "import tldextract\n",
    "import socket\n",
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a9cf4fc",
   "metadata": {},
   "source": [
    "# **URL_Features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6dc0ac73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import tldextract\n",
    "\n",
    "def check_redirects(url):\n",
    "    try:\n",
    "        if not url.startswith(\"http://\") and not url.startswith(\"https://\"):\n",
    "            url = \"https://\" + url\n",
    "        \n",
    "        original_domain = tldextract.extract(url).registered_domain\n",
    "        response = requests.get(url, timeout=10, allow_redirects=True)\n",
    "\n",
    "        final_url = response.url\n",
    "        final_domain = tldextract.extract(final_url).registered_domain\n",
    "\n",
    "        redirected = len(response.history) > 0\n",
    "        internal_redirect = redirected and (original_domain == final_domain)\n",
    "        external_redirect = redirected and (original_domain != final_domain)\n",
    "\n",
    "        return {\n",
    "            \"f38_redirect_count\": len(response.history),\n",
    "            \"f39_external_redirect\": int(external_redirect)\n",
    "        }\n",
    "    except Exception as e:\n",
    "        return {\n",
    "            \"f38_redirect_count\": 0,\n",
    "            \"f39_external_redirect\": 0,\n",
    "            \"redirect_error\": str(e)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d681ef02",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_url_features(url):\n",
    "    if not url.startswith(\"http://\") and not url.startswith(\"https://\"):\n",
    "        url = \"https://\" + url \n",
    "    features = {}\n",
    "    parsed = urlparse(url)\n",
    "    ext = tldextract.extract(url)\n",
    "\n",
    "    domain = ext.domain\n",
    "    full_url = url\n",
    "    hostname = parsed.hostname if parsed.hostname else \"\"\n",
    "\n",
    "    # f1-2: URL and hostname length\n",
    "    features['url_length'] = full_url\n",
    "    features[\"f1_url_length\"] = len(full_url)\n",
    "    features[\"f2_hostname_length\"] = len(hostname)\n",
    "\n",
    "    # f3: IP in hostname\n",
    "    try:\n",
    "        socket.inet_aton(hostname)\n",
    "        features[\"f3_ip_in_url\"] = 1\n",
    "    except:\n",
    "        features[\"f3_ip_in_url\"] = int(bool(re.search(r\"\\d+\\.\\d+\\.\\d+\\.\\d+\", hostname)))\n",
    "\n",
    "    # f4–f20: special characters\n",
    "    special_chars = ['.', '-', '@', '?', '&', '|', '=', '_', '~', '%', '/', '*', ':', ',', ';', '$', ' ']\n",
    "    for i, char in enumerate(special_chars, start=4):\n",
    "        features[f\"f{i}_count_{repr(char)}\"] = full_url.count(char)\n",
    "\n",
    "    # f21–f24: common phishing terms\n",
    "    features[\"f21_www_count\"] = full_url.lower().count(\"www\")\n",
    "    features[\"f22_com_count\"] = full_url.lower().count(\".com\")\n",
    "    features[\"f23_http_count\"] = full_url.lower().count(\"http://\")\n",
    "    features[\"f24_double_slash\"] = full_url.count(\"//\")\n",
    "\n",
    "    # f25: HTTPS token\n",
    "    features[\"f25_https\"] = int(url.startswith(\"https://\"))\n",
    "\n",
    "    # f26–f27: ratio of digits\n",
    "    num_digits_url = sum(c.isdigit() for c in url)\n",
    "    num_digits_host = sum(c.isdigit() for c in hostname)\n",
    "    features[\"f26_digit_ratio_url\"] = num_digits_url / len(url) if url else 0\n",
    "    features[\"f27_digit_ratio_host\"] = num_digits_host / len(hostname) if hostname else 0\n",
    "\n",
    "    # f28: punycode\n",
    "    features[\"f28_punycode\"] = int(\"xn--\" in hostname)\n",
    "\n",
    "    # f29: port present\n",
    "    features[\"f29_port_in_url\"] = int(\":\" in hostname)\n",
    "\n",
    "    # f30–f31: TLD in path/subdomain\n",
    "    tld = ext.suffix\n",
    "    features[\"f30_tld_in_path\"] = int(tld in parsed.path)\n",
    "    features[\"f31_tld_in_subdomain\"] = int(tld in ext.subdomain)\n",
    "\n",
    "    # f32: abnormal subdomain\n",
    "    features[\"f32_abnormal_subdomain\"] = int(bool(re.match(r\"w[w\\d]{1,}\\d+\", ext.subdomain)))\n",
    "\n",
    "    # f33: number of subdomains\n",
    "    features[\"f33_num_subdomains\"] = len(ext.subdomain.split(\".\")) if ext.subdomain else 0\n",
    "\n",
    "    # f34: prefix/suffix in domain\n",
    "    features[\"f34_prefix_suffix\"] = int(\"-\" in ext.domain)\n",
    "\n",
    "    # f35: random-looking domain (simple consonant cluster rule)\n",
    "    features[\"f35_random_domain\"] = int(bool(re.search(r\"[bcdfghjklmnpqrstvwxyz]{4,}\", ext.domain.lower())))\n",
    "\n",
    "    # f36: shortening service\n",
    "    shortening_services = ['bit.ly', 'tinyurl.com', 'goo.gl', 'ow.ly', 'is.gd', 'buff.ly', 't.co']\n",
    "    features[\"f36_shortening_service\"] = int(any(service in hostname for service in shortening_services))\n",
    "\n",
    "    # f37: Suspicious file extensions\n",
    "    path = parsed.path.lower()\n",
    "    features[\"f37_suspicious_extension\"] = int(any(ext in path for ext in ['.txt', '.exe', '.js']))\n",
    "\n",
    "    # f38–f39: Redirects (hardcoded as example – requires content-based check for real)\n",
    "    features[\"f38_redirect_count\"] = check_redirects(full_url)[\"f38_redirect_count\"]\n",
    "    features[\"f39_external_redirect\"] = check_redirects(full_url)[\"f39_external_redirect\"]\n",
    "\n",
    "    # f40–f50: NLP features (stub only)\n",
    "    words = re.findall(r'\\w+', full_url)\n",
    "    features[\"f40_word_count\"] = len(words)\n",
    "    features[\"f41_char_repeat\"] = max((full_url.count(c) for c in set(full_url)), default=0)\n",
    "    features[\"f42_shortest_word_url\"] = min((len(w) for w in words), default=0)\n",
    "    features[\"f43_shortest_word_host\"] = min((len(w) for w in hostname.split(\".\")), default=0)\n",
    "    features[\"f44_shortest_word_path\"] = min((len(w) for w in parsed.path.split(\"/\") if w), default=0)\n",
    "    features[\"f45_longest_word_url\"] = max((len(w) for w in words), default=0)\n",
    "    features[\"f46_longest_word_host\"] = max((len(w) for w in hostname.split(\".\")), default=0)\n",
    "    features[\"f47_longest_word_path\"] = max((len(w) for w in parsed.path.split(\"/\") if w), default=0)\n",
    "    features[\"f48_avg_word_url\"] = sum(len(w) for w in words) / len(words) if words else 0\n",
    "    features[\"f49_avg_word_host\"] = sum(len(w) for w in hostname.split(\".\")) / len(hostname.split(\".\")) if hostname else 0\n",
    "    path_words = [w for w in parsed.path.split(\"/\") if w]\n",
    "    features[\"f50_avg_word_path\"] = sum(len(w) for w in path_words) / len(path_words) if path_words else 0\n",
    "\n",
    "    # f51: Sensitive keywords (phishing hints)\n",
    "    hints = ['verify', 'update', 'account', 'secure', 'bank', 'signin', 'login']\n",
    "    features[\"f51_phish_hints\"] = sum(hint in full_url.lower() for hint in hints)\n",
    "\n",
    "    # f52–f54: Brand domains\n",
    "    brand_list = ['paypal', 'apple', 'amazon', 'facebook', 'google', 'netflix']\n",
    "    features[\"f52_brand_in_domain\"] = int(any(brand in ext.domain for brand in brand_list))\n",
    "    features[\"f53_brand_in_subdomain\"] = int(any(brand in ext.subdomain for brand in brand_list))\n",
    "    features[\"f54_brand_in_path\"] = int(any(brand in parsed.path for brand in brand_list))\n",
    "\n",
    "    # f55: Suspicious TLDs\n",
    "    suspicious_tlds = ['tk', 'ml', 'ga', 'cf', 'gq', 'cn', 'ru']\n",
    "    features[\"f55_suspicious_tld\"] = int(tld in suspicious_tlds)\n",
    "\n",
    "    # f56: Statistical report (placeholder)\n",
    "    with open(\"PhishingLink\\\\knownip.txt\", \"r\") as f:\n",
    "        known_malicious_ips = [line.strip() for line in f if line.strip()]\n",
    "    features[\"f56_known_malicious_ip\"] = int(hostname in known_malicious_ips)\n",
    "\n",
    "    return features\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba22a172",
   "metadata": {},
   "source": [
    "# **HTML Content Features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "515f9d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_full_feature_set(url):\n",
    "    if not url.startswith(\"http://\") and not url.startswith(\"https://\"):\n",
    "        url = \"https://\" + url \n",
    "    try:\n",
    "        response = requests.get(url, timeout=10)\n",
    "        html = response.text\n",
    "        soup = BeautifulSoup(html, \"html.parser\")\n",
    "        domain = tldextract.extract(url).domain\n",
    "\n",
    "        links = soup.find_all(\"a\", href=True)\n",
    "        total_links = len(links)\n",
    "        internal_links = 0\n",
    "        external_links = 0\n",
    "        null_links = 0\n",
    "        safe_anchors = 0\n",
    "        internal_errors = 0\n",
    "        external_errors = 0\n",
    "\n",
    "        for link in links:\n",
    "            href = link['href']\n",
    "            if href.startswith('#') or 'void' in href:\n",
    "                null_links += 1\n",
    "                safe_anchors += 1\n",
    "            elif 'javascript' in href or 'mailto:' in href:\n",
    "                safe_anchors += 1\n",
    "            elif domain in href:\n",
    "                internal_links += 1\n",
    "            else:\n",
    "                external_links += 1\n",
    "\n",
    "        # Redirections\n",
    "        internal_redirects = html.count('location.href') + html.count('window.location')\n",
    "        external_redirects = html.count('window.open')\n",
    "\n",
    "        # CSS features\n",
    "        stylesheets = soup.find_all(\"link\", rel=\"stylesheet\")\n",
    "        external_css = sum(1 for s in stylesheets if domain not in s.get(\"href\", \"\"))\n",
    "\n",
    "        link_tags = soup.find_all(\"link\", href=True)\n",
    "        links_in_tags = sum(1 for tag in link_tags if domain in tag[\"href\"])\n",
    "\n",
    "        # Media\n",
    "        media_tags = soup.find_all(['img', 'audio', 'video'])\n",
    "        internal_media = sum(1 for m in media_tags if domain in m.get('src', ''))\n",
    "        external_media = len(media_tags) - internal_media\n",
    "\n",
    "        # Forms\n",
    "        login_forms = sum(1 for f in soup.find_all(\"form\") if any(k in f.get(\"action\", \"\").lower() for k in [\"login\", \"signin\", \"verify\"]))\n",
    "        empty_forms = sum(1 for f in soup.find_all(\"form\") if f.get(\"action\", \"\") in [\"\", \"about:blank\"])\n",
    "        submit_to_email = sum(1 for f in soup.find_all(\"form\") if \"mailto:\" in f.get(\"action\", \"\"))\n",
    "\n",
    "        # Title and copyright\n",
    "        title = soup.title.string.strip() if soup.title else \"\"\n",
    "        has_domain_in_title = int(domain in title)\n",
    "        empty_title = int(title == \"\")\n",
    "        domain_in_copyright = int(domain in soup.get_text().lower())\n",
    "\n",
    "        # iframes\n",
    "        invisible_iframes = sum(1 for i in soup.find_all(\"iframe\") if \"display:none\" in i.get(\"style\", \"\") or \"visibility:hidden\" in i.get(\"style\", \"\"))\n",
    "\n",
    "        # JS unsafe interaction\n",
    "        disable_right_click = int(\"onmousedown\" in html)\n",
    "        onmouseover_right_click = int(\"event.button==2\" in html)\n",
    "\n",
    "        # Favicon\n",
    "        favicons = soup.find_all(\"link\", rel=lambda x: x and 'icon' in x)\n",
    "        external_favicon = sum(1 for f in favicons if domain not in f.get(\"href\", \"\"))\n",
    "\n",
    "        return {\n",
    "            \"f57_total_links\": total_links,\n",
    "            \"f58_ratio_internal_links\": internal_links / total_links if total_links else 0,\n",
    "            \"f59_ratio_external_links\": external_links / total_links if total_links else 0,\n",
    "            \"f60_ratio_null_links\": null_links / total_links if total_links else 0,\n",
    "            \"f61_external_css\": external_css,\n",
    "            \"f62_internal_redirects\": internal_redirects,\n",
    "            \"f63_external_redirects\": external_redirects,\n",
    "            \"f64_internal_errors\": internal_errors,\n",
    "            \"f65_external_errors\": external_errors,\n",
    "            \"f66_login_forms\": login_forms,\n",
    "            \"f67_external_favicon\": int(external_favicon > 0),\n",
    "            \"f68_links_in_tags\": links_in_tags / len(link_tags) if link_tags else 0,\n",
    "            \"f69_submit_to_email\": submit_to_email,\n",
    "            \"f70_internal_media\": internal_media,\n",
    "            \"f71_external_media\": external_media,\n",
    "            \"f72_empty_forms\": empty_forms,\n",
    "            \"f73_invisible_iframes\": invisible_iframes,\n",
    "            \"f74_popups\": html.count(\"window.alert\"),\n",
    "            \"f75_safe_anchors\": safe_anchors,\n",
    "            \"f76_disable_right_click\": disable_right_click,\n",
    "            \"f77_onmouseover_rightclick\": onmouseover_right_click,\n",
    "            \"f78_empty_title\": empty_title,\n",
    "            \"f79_domain_in_title\": has_domain_in_title,\n",
    "            \"f80_domain_in_copyright\": domain_in_copyright\n",
    "        }\n",
    "\n",
    "    except Exception as e:\n",
    "        return {\"url\": url, \"error\": str(e)}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebcdf57e",
   "metadata": {},
   "source": [
    "# **External_Features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0f2bdde2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import whois\n",
    "import socket\n",
    "import requests\n",
    "import datetime\n",
    "from urllib.parse import urlparse\n",
    "import os\n",
    "from dotenv import load_dotenv \n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "api_key=os.getenv('OR_api_key')\n",
    "\n",
    "def extract_external_features(url, openpagerank_api_key=api_key):\n",
    "    features = {}\n",
    "    try:\n",
    "        # Parse domain\n",
    "        hostname = urlparse(url).hostname\n",
    "        if hostname is None:\n",
    "            return {\"error\": \"Invalid URL\"}\n",
    "\n",
    "        # f81: WHOIS registered\n",
    "        try:\n",
    "            w = whois.whois(hostname)\n",
    "            features[\"f81_whois_registered\"] = int(w.domain_name is not None)\n",
    "        except:\n",
    "            features[\"f81_whois_registered\"] = 0\n",
    "\n",
    "        # f82: Domain registration length (in years)\n",
    "        try:\n",
    "            expiration = w.expiration_date\n",
    "            creation = w.creation_date\n",
    "\n",
    "            # Handle multiple date entries\n",
    "            if isinstance(expiration, list): expiration = expiration[0]\n",
    "            if isinstance(creation, list): creation = creation[0]\n",
    "\n",
    "            delta = (expiration - creation).days / 365 if expiration and creation else 0\n",
    "            features[\"f82_registration_years\"] = round(delta, 2)\n",
    "        except:\n",
    "            features[\"f82_registration_years\"] = 0\n",
    "\n",
    "        # f83: Domain age (in days)\n",
    "        try:\n",
    "            creation = w.creation_date\n",
    "            if isinstance(creation, list): creation = creation[0]\n",
    "            domain_age = (datetime.datetime.now() - creation).days\n",
    "            features[\"f83_domain_age_days\"] = domain_age\n",
    "        except:\n",
    "            features[\"f83_domain_age_days\"] = 0\n",
    "\n",
    "        # f84: Web traffic (Not directly accessible from Alexa anymore)\n",
    "        features[\"f84_web_traffic\"] = -1  # -1 means unknown, deprecated via Alexa\n",
    "\n",
    "        # f85: DNS record present\n",
    "        try:\n",
    "            socket.gethostbyname(hostname)\n",
    "            features[\"f85_dns_record\"] = 1\n",
    "        except socket.error:\n",
    "            features[\"f85_dns_record\"] = 0\n",
    "\n",
    "        # f86: Google index (basic method using site: query)\n",
    "        google_query = f\"https://www.google.com/search?q=site:{hostname}\"\n",
    "        headers = {'User-Agent': 'Mozilla/5.0'}\n",
    "        response = requests.get(google_query, headers=headers, timeout=5)\n",
    "        features[\"f86_google_indexed\"] = int(\"did not match any documents\" not in response.text.lower())\n",
    "\n",
    "        # f87: PageRank via OpenPageRank API (Optional)\n",
    "        if openpagerank_api_key:\n",
    "            pr_response = requests.get(\n",
    "                \"https://openpagerank.com/api/v1.0/getPageRank\",\n",
    "                headers={\"API-OPR\": openpagerank_api_key},\n",
    "                params={\"domains[]\": hostname},\n",
    "            )\n",
    "            if pr_response.status_code == 200:\n",
    "                rank = pr_response.json()[\"response\"][0].get(\"page_rank_integer\", -1)\n",
    "                features[\"f87_pagerank\"] = rank\n",
    "            else:\n",
    "                features[\"f87_pagerank\"] = -1\n",
    "        else:\n",
    "            features[\"f87_pagerank\"] = -1\n",
    "\n",
    "    except Exception as e:\n",
    "        features[\"error\"] = str(e)\n",
    "\n",
    "    return features\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eb0e307",
   "metadata": {},
   "source": [
    "# **Test**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3ba6703d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'url_length': 'https://www.todayshomeowner.com/how-to-make-homemade-insecticidal-soap-for-plants/', 'f1_url_length': 82, 'f2_hostname_length': 23, 'f3_ip_in_url': 0, \"f4_count_'.'\": 2, \"f5_count_'-'\": 7, \"f6_count_'@'\": 0, \"f7_count_'?'\": 0, \"f8_count_'&'\": 0, \"f9_count_'|'\": 0, \"f10_count_'='\": 0, \"f11_count_'_'\": 0, \"f12_count_'~'\": 0, \"f13_count_'%'\": 0, \"f14_count_'/'\": 4, \"f15_count_'*'\": 0, \"f16_count_':'\": 1, \"f17_count_','\": 0, \"f18_count_';'\": 0, \"f19_count_'$'\": 0, \"f20_count_' '\": 0, 'f21_www_count': 1, 'f22_com_count': 1, 'f23_http_count': 0, 'f24_double_slash': 1, 'f25_https': 1, 'f26_digit_ratio_url': 0.0, 'f27_digit_ratio_host': 0.0, 'f28_punycode': 0, 'f29_port_in_url': 0, 'f30_tld_in_path': 0, 'f31_tld_in_subdomain': 0, 'f32_abnormal_subdomain': 0, 'f33_num_subdomains': 1, 'f34_prefix_suffix': 0, 'f35_random_domain': 0, 'f36_shortening_service': 0, 'f37_suspicious_extension': 0, 'f38_redirect_count': 1, 'f39_external_redirect': 0, 'f40_word_count': 12, 'f41_char_repeat': 9, 'f42_shortest_word_url': 2, 'f43_shortest_word_host': 3, 'f44_shortest_word_path': 49, 'f45_longest_word_url': 15, 'f46_longest_word_host': 15, 'f47_longest_word_path': 49, 'f48_avg_word_url': 5.666666666666667, 'f49_avg_word_host': 7.0, 'f50_avg_word_path': 49.0, 'f51_phish_hints': 0, 'f52_brand_in_domain': 0, 'f53_brand_in_subdomain': 0, 'f54_brand_in_path': 0, 'f55_suspicious_tld': 0, 'f56_known_malicious_ip': 0}\n",
      "url_length: https://www.todayshomeowner.com/how-to-make-homemade-insecticidal-soap-for-plants/\n",
      "f1_url_length: 82\n",
      "f2_hostname_length: 23\n",
      "f3_ip_in_url: 0\n",
      "f4_count_'.': 2\n",
      "f5_count_'-': 7\n",
      "f6_count_'@': 0\n",
      "f7_count_'?': 0\n",
      "f8_count_'&': 0\n",
      "f9_count_'|': 0\n",
      "f10_count_'=': 0\n",
      "f11_count_'_': 0\n",
      "f12_count_'~': 0\n",
      "f13_count_'%': 0\n",
      "f14_count_'/': 4\n",
      "f15_count_'*': 0\n",
      "f16_count_':': 1\n",
      "f17_count_',': 0\n",
      "f18_count_';': 0\n",
      "f19_count_'$': 0\n",
      "f20_count_' ': 0\n",
      "f21_www_count: 1\n",
      "f22_com_count: 1\n",
      "f23_http_count: 0\n",
      "f24_double_slash: 1\n",
      "f25_https: 1\n",
      "f26_digit_ratio_url: 0.0\n",
      "f27_digit_ratio_host: 0.0\n",
      "f28_punycode: 0\n",
      "f29_port_in_url: 0\n",
      "f30_tld_in_path: 0\n",
      "f31_tld_in_subdomain: 0\n",
      "f32_abnormal_subdomain: 0\n",
      "f33_num_subdomains: 1\n",
      "f34_prefix_suffix: 0\n",
      "f35_random_domain: 0\n",
      "f36_shortening_service: 0\n",
      "f37_suspicious_extension: 0\n",
      "f38_redirect_count: 1\n",
      "f39_external_redirect: 0\n",
      "f40_word_count: 12\n",
      "f41_char_repeat: 9\n",
      "f42_shortest_word_url: 2\n",
      "f43_shortest_word_host: 3\n",
      "f44_shortest_word_path: 49\n",
      "f45_longest_word_url: 15\n",
      "f46_longest_word_host: 15\n",
      "f47_longest_word_path: 49\n",
      "f48_avg_word_url: 5.666666666666667\n",
      "f49_avg_word_host: 7.0\n",
      "f50_avg_word_path: 49.0\n",
      "f51_phish_hints: 0\n",
      "f52_brand_in_domain: 0\n",
      "f53_brand_in_subdomain: 0\n",
      "f54_brand_in_path: 0\n",
      "f55_suspicious_tld: 0\n",
      "f56_known_malicious_ip: 0\n"
     ]
    }
   ],
   "source": [
    "url='https://www.todayshomeowner.com/how-to-make-homemade-insecticidal-soap-for-plants/'\n",
    "URL_features = extract_url_features(url)\n",
    "print(URL_features)\n",
    "for k, v in URL_features.items():\n",
    "    print(f\"{k}: {v}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7a71073a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f57_total_links: 161\n",
      "f58_ratio_internal_links: 0.7763975155279503\n",
      "f59_ratio_external_links: 0.13664596273291926\n",
      "f60_ratio_null_links: 0.08074534161490683\n",
      "f61_external_css: 1\n",
      "f62_internal_redirects: 2\n",
      "f63_external_redirects: 0\n",
      "f64_internal_errors: 0\n",
      "f65_external_errors: 0\n",
      "f66_login_forms: 0\n",
      "f67_external_favicon: 0\n",
      "f68_links_in_tags: 0.8695652173913043\n",
      "f69_submit_to_email: 0\n",
      "f70_internal_media: 18\n",
      "f71_external_media: 0\n",
      "f72_empty_forms: 0\n",
      "f73_invisible_iframes: 1\n",
      "f74_popups: 0\n",
      "f75_safe_anchors: 14\n",
      "f76_disable_right_click: 0\n",
      "f77_onmouseover_rightclick: 0\n",
      "f78_empty_title: 0\n",
      "f79_domain_in_title: 0\n",
      "f80_domain_in_copyright: 1\n"
     ]
    }
   ],
   "source": [
    "Html_features = extract_full_feature_set(url)\n",
    "for k, v in Html_features.items():\n",
    "    print(f\"{k}: {v}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cffa9981",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f81_whois_registered: 0\n",
      "f82_registration_years: 0\n",
      "f83_domain_age_days: 0\n",
      "f84_web_traffic: -1\n",
      "f85_dns_record: 1\n",
      "f86_google_indexed: 1\n",
      "f87_pagerank: 5\n"
     ]
    }
   ],
   "source": [
    "Ex_features=extract_external_features(url)\n",
    "for k, v in Ex_features.items():\n",
    "    print(f\"{k}: {v}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
